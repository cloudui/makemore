{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3672e4-f026-460d-bd26-6b5b4cd6ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2731e8b0-4c23-4f01-9f70-e7910cf4e63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15fbc05d-c108-4bd2-b589-8b7b3942d053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.647196292877197e-07"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgt = 0\n",
    "n = 1000000\n",
    "for _ in range(n): \n",
    "    t1 = time.time()\n",
    "    a*a\n",
    "    t2 = time.time()\n",
    "    avgt += (t2-t1)\n",
    "\n",
    "avgt/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26665b80-6eee-48bd-9324-d929c1f96e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Python Native Types ---\n",
      "int a*a: 0.220832 seconds\n",
      "int a**2: 0.272007 seconds\n",
      "float a*a: 0.133946 seconds\n",
      "float a**2: 0.386424 seconds\n",
      "\n",
      "--- NumPy Arrays (element-wise) ---\n",
      "NumPy small array a*a: 0.289032 seconds\n",
      "NumPy small array a**2: 0.291680 seconds\n",
      "NumPy large array a*a: 803.603341 seconds\n",
      "NumPy large array a**2: 774.972181 seconds\n",
      "\n",
      "--- PyTorch Tensors (element-wise) ---\n",
      "PyTorch small tensor a*a: 1.074584 seconds\n",
      "PyTorch small tensor a**2: 1.406311 seconds\n",
      "PyTorch large CPU tensor a*a: 214.873103 seconds\n",
      "PyTorch large CPU tensor a**2: 231.010704 seconds\n",
      "\n",
      "CUDA not available, skipping GPU tensor benchmark.\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Python Native Types ---\n",
    "print(\"--- Python Native Types ---\")\n",
    "a_int = 123456789\n",
    "a_float = 123.456789\n",
    "\n",
    "time_aa_int = timeit.timeit('a_int * a_int', globals=locals(), number=10000000)\n",
    "time_a_pow2_int = timeit.timeit('a_int ** 2', globals=locals(), number=10000000)\n",
    "print(f\"int a*a: {time_aa_int:.6f} seconds\")\n",
    "print(f\"int a**2: {time_a_pow2_int:.6f} seconds\")\n",
    "\n",
    "time_aa_float = timeit.timeit('a_float * a_float', globals=locals(), number=10000000)\n",
    "time_a_pow2_float = timeit.timeit('a_float ** 2', globals=locals(), number=10000000)\n",
    "print(f\"float a*a: {time_aa_float:.6f} seconds\")\n",
    "print(f\"float a**2: {time_a_pow2_float:.6f} seconds\")\n",
    "\n",
    "\n",
    "# --- 2. NumPy Arrays ---\n",
    "print(\"\\n--- NumPy Arrays (element-wise) ---\")\n",
    "# Using a small array\n",
    "a_np_small = np.array([1.2, 3.4, 5.6])\n",
    "time_np_aa_small = timeit.timeit('a_np_small * a_np_small', globals=locals())\n",
    "time_np_a_pow2_small = timeit.timeit('a_np_small ** 2', globals=locals())\n",
    "print(f\"NumPy small array a*a: {time_np_aa_small:.6f} seconds\")\n",
    "print(f\"NumPy small array a**2: {time_np_a_pow2_small:.6f} seconds\")\n",
    "\n",
    "# Using a larger array\n",
    "a_np_large = np.random.rand(1000000) # One million elements\n",
    "time_np_aa_large = timeit.timeit('a_np_large * a_np_large', globals=locals())\n",
    "time_np_a_pow2_large = timeit.timeit('a_np_large ** 2', globals=locals())\n",
    "print(f\"NumPy large array a*a: {time_np_aa_large:.6f} seconds\")\n",
    "print(f\"NumPy large array a**2: {time_np_a_pow2_large:.6f} seconds\")\n",
    "\n",
    "\n",
    "# --- 3. PyTorch Tensors ---\n",
    "print(\"\\n--- PyTorch Tensors (element-wise) ---\")\n",
    "# Using a small tensor\n",
    "a_torch_small = torch.tensor([1.2, 3.4, 5.6])\n",
    "time_torch_aa_small = timeit.timeit('a_torch_small * a_torch_small', globals=locals())\n",
    "time_torch_a_pow2_small = timeit.timeit('a_torch_small ** 2', globals=locals())\n",
    "print(f\"PyTorch small tensor a*a: {time_torch_aa_small:.6f} seconds\")\n",
    "print(f\"PyTorch small tensor a**2: {time_torch_a_pow2_small:.6f} seconds\")\n",
    "\n",
    "# Using a larger tensor (CPU)\n",
    "a_torch_large_cpu = torch.randn(1000000)\n",
    "time_torch_aa_large_cpu = timeit.timeit('a_torch_large_cpu * a_torch_large_cpu', globals=locals())\n",
    "time_torch_a_pow2_large_cpu = timeit.timeit('a_torch_large_cpu ** 2', globals=locals())\n",
    "print(f\"PyTorch large CPU tensor a*a: {time_torch_aa_large_cpu:.6f} seconds\")\n",
    "print(f\"PyTorch large CPU tensor a**2: {time_torch_a_pow2_large_cpu:.6f} seconds\")\n",
    "\n",
    "# Using a larger tensor (GPU, if available)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\n--- PyTorch Tensors (GPU) ---\")\n",
    "    a_torch_large_gpu = torch.randn(1000000).cuda()\n",
    "    # Important: Synchronize CUDA operations for accurate timing\n",
    "    # The first time through might include kernel launch overhead\n",
    "    time_torch_aa_large_gpu = timeit.timeit('torch.cuda.synchronize(); a_torch_large_gpu * a_torch_large_gpu; torch.cuda.synchronize()', globals=locals())\n",
    "    time_torch_a_pow2_large_gpu = timeit.timeit('torch.cuda.synchronize(); a_torch_large_gpu ** 2; torch.cuda.synchronize()', globals=locals())\n",
    "    print(f\"PyTorch large GPU tensor a*a: {time_torch_aa_large_gpu:.6f} seconds\")\n",
    "    print(f\"PyTorch large GPU tensor a**2: {time_torch_a_pow2_large_gpu:.6f} seconds\")\n",
    "else:\n",
    "    print(\"\\nCUDA not available, skipping GPU tensor benchmark.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c8555e-3333-4638-a341-97a52994ca8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
